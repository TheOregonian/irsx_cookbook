{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump salaries from 990EZ in OR (continuing from part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodecsv as csv\n",
    "from irsx.xmlrunner import XMLRunner\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the whole file of orgs with efilings from part 1 here, it's not very long\n",
    "file_rows = [] \n",
    "# We're using the output of part 1\n",
    "with open('orefilers.csv', 'rb') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    for row in reader:\n",
    "        file_rows.append(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the name of the output file\n",
    "outfilename =\"ez_comp_1.csv\"\n",
    "outfile = open(outfilename , 'wb')\n",
    "\n",
    "# the header rows as they'll appear in the output\n",
    "headers = [\"period\", \"ein\", \"object_id\", \"taxpayer_name\", \"name\", \"business_name1\", \"business_name2\", \"title\", \"org_comp\", \"related_comp\", \"other_comp\", \"gross_receipts\"]\n",
    "# start up a dictwriter, ignore extra rows\n",
    "dw = csv.DictWriter(outfile, headers, extrasaction='ignore')\n",
    "dw.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an XMLRunner -- this is what actually does the parsing\n",
    "xml_runner = XMLRunner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out what to extract\n",
    "\n",
    "Data from each repeating group should go to it's own file, otherwise it won't make sense.\n",
    "\n",
    "To figure out what to capture, I started by looking at schedule J: http://www.irsx.info/#IRS990ScheduleJ\n",
    "Then I went to the table details and picked the rows I wanted from the repeating group:\n",
    "http://www.irsx.info/metadata/groups/SkdJRltdOrgOffcrTrstKyEmpl.html\n",
    "\n",
    "Note that it's common for director/employee names in schedule J to get listed as businessname.\n",
    "\n",
    "Also note that IRSx checks to see if a file has been downloaded before fetching it. Running this the first time will be slow if the filings aren't already downloaded, but much faster if they've already been downloaded.\n",
    "\n",
    "-------NOTE--------\n",
    "Edited to get compensation from EZ partIV, not sked j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filing version 2017v2.3 isn't supported for this operation\n",
      "Filing version 2017v2.3 isn't supported for this operation\n",
      "Filing version 2017v2.3 isn't supported for this operation\n",
      "Filing version 2017v2.3 isn't supported for this operation\n",
      "Filing version 2017v2.3 isn't supported for this operation\n"
     ]
    }
   ],
   "source": [
    "DEMO_MAX = 10\n",
    "num_rows = 0\n",
    "\n",
    "for row in file_rows:\n",
    "    num_rows += 1\n",
    "    this_object_id = row['OBJECT_ID']\n",
    "    parsed_filing = xml_runner.run_filing(this_object_id)\n",
    "    \n",
    "    # if it somehow busted, just note it and continue\n",
    "    if not parsed_filing:\n",
    "        print(\"Skipping filing %s(filings with pre-2013 schemas are skipped)\\n row details: %s\" % (this_object_id, row))\n",
    "        continue \n",
    "    \n",
    "    schedule_list = parsed_filing.list_schedules()\n",
    "    if 'IRS990EZ' in schedule_list:\n",
    "        \n",
    "        # store the output in this dict\n",
    "        outputdata = {}\n",
    "        # assign some initial values from the input csv\n",
    "        outputdata['period'] = row['TAX_PERIOD_x']\n",
    "        outputdata['ein'] = row['EIN']\n",
    "        outputdata['object_id'] = row['OBJECT_ID']\n",
    "        outputdata['taxpayer_name'] = row['TAXPAYER_NAME']\n",
    "        \n",
    "        # some schedules can appear multiple times, but irs990 only appears once\n",
    "        # so we grab the first one \n",
    "        parsed_main = parsed_filing.get_parsed_sked('IRS990EZ')[0] \n",
    "        \n",
    "        \n",
    "        print(parsed_main)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         # now use the table name we looked up -- that's where we find it\n",
    "#         try:\n",
    "#             # repeating groups are returned as an array of dicts\n",
    "#             employee_groups = parsed_main['groups']['Frm990PrtVIISctnA']\n",
    "#         except KeyError:\n",
    "#             print(\"No Frm990PrtVIISctnA found in %s skipping\" % this_object_id)\n",
    "#             continue\n",
    "          \n",
    "#         # read through each employee and pull out the data we want\n",
    "#         for employee_group in employee_groups:\n",
    "            \n",
    "#             # That leaves the following values to come from schedule J if there is one\n",
    "#             # \"name\", \"business_name1\", \"business_name2\", \"title\", \"org_comp\", \"related_comp\"\n",
    "#             # those keys come from the headers we gave dictwriter before\n",
    "#             outputdata['name'] = employee_group.get('PrsnNm')\n",
    "#             outputdata['business_name1'] = employee_group.get('BsnssNmLn1Txt')\n",
    "#             outputdata['business_name2'] = employee_group.get('BsnssNmLn2Txt')\n",
    "#             outputdata['title'] = employee_group.get('TtlTxt')\n",
    "#             outputdata['org_comp'] = employee_group.get('RprtblCmpFrmOrgAmt')  \n",
    "#             outputdata['related_comp'] = employee_group.get('RprtblCmpFrmRltdOrgAmt')\n",
    "#             outputdata['other_comp'] = employee_group.get('OthrCmpnstnAmt')\n",
    "        \n",
    "#             dw.writerow(outputdata)\n",
    "        \n",
    "#     else:\n",
    "#         print(\"No 990 in filing %s, skipping\" % this_object_id)\n",
    "\n",
    "    # Don't run endlessly during a demo:\n",
    "    if(num_rows > DEMO_MAX):\n",
    "       break\n",
    "    if num_rows%100==0:\n",
    "        print(\"Processed %s filings\" % num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>ein</th>\n",
       "      <th>object_id</th>\n",
       "      <th>taxpayer_name</th>\n",
       "      <th>name</th>\n",
       "      <th>business_name1</th>\n",
       "      <th>business_name2</th>\n",
       "      <th>title</th>\n",
       "      <th>org_comp</th>\n",
       "      <th>related_comp</th>\n",
       "      <th>other_comp</th>\n",
       "      <th>gross_receipts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [period, ein, object_id, taxpayer_name, name, business_name1, business_name2, title, org_comp, related_comp, other_comp, gross_receipts]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# close the outfile\n",
    "outfile.close()\n",
    "\n",
    "sked_j_ore_efilers = pd.read_csv(outfilename)\n",
    "sked_j_ore_efilers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
